{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327a30bd-0a8a-4078-9667-6a435a56e2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m25\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">481</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m481\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">481</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m481\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 304ms/step - loss: 1051906.3750 - mae: 980.8104 - val_loss: 1325222.5000 - val_mae: 1138.2988\n",
      "Epoch 2/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1115816.3750 - mae: 1011.2554 - val_loss: 1254427.7500 - val_mae: 1107.3427\n",
      "Epoch 3/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 937595.0625 - mae: 906.6653 - val_loss: 1185922.3750 - val_mae: 1076.5120\n",
      "Epoch 4/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 910615.0625 - mae: 897.8336 - val_loss: 1120509.8750 - val_mae: 1046.2659\n",
      "Epoch 5/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 919944.4375 - mae: 886.9062 - val_loss: 1057632.7500 - val_mae: 1016.3414\n",
      "Epoch 6/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 873984.0000 - mae: 860.4604 - val_loss: 995103.8750 - val_mae: 985.7347\n",
      "Epoch 7/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 819406.8750 - mae: 861.5610 - val_loss: 933382.1875 - val_mae: 954.6107\n",
      "Epoch 8/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 791993.6875 - mae: 863.2029 - val_loss: 874649.8125 - val_mae: 924.0519\n",
      "Epoch 9/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 793606.9375 - mae: 859.8977 - val_loss: 817321.5000 - val_mae: 893.1940\n",
      "Epoch 10/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 756807.8125 - mae: 839.9100 - val_loss: 763773.0000 - val_mae: 863.2614\n",
      "Epoch 11/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 559963.2500 - mae: 700.2866 - val_loss: 712691.1250 - val_mae: 833.7096\n",
      "Epoch 12/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 743568.5000 - mae: 823.8137 - val_loss: 663422.9375 - val_mae: 804.1796\n",
      "Epoch 13/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 746698.1875 - mae: 841.0923 - val_loss: 615942.5000 - val_mae: 774.6572\n",
      "Epoch 14/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 486196.0000 - mae: 638.1987 - val_loss: 571352.3750 - val_mae: 745.9435\n",
      "Epoch 15/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 488738.6875 - mae: 637.4493 - val_loss: 529294.8750 - val_mae: 717.8691\n",
      "Epoch 16/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 518375.9062 - mae: 645.7789 - val_loss: 489406.2500 - val_mae: 690.2095\n",
      "Epoch 17/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 488928.2500 - mae: 650.6306 - val_loss: 451273.3438 - val_mae: 662.7059\n",
      "Epoch 18/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 527498.7500 - mae: 687.0656 - val_loss: 414320.2500 - val_mae: 634.8587\n",
      "Epoch 19/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 371146.1875 - mae: 557.0127 - val_loss: 379921.9062 - val_mae: 607.6808\n",
      "Epoch 20/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 422342.8125 - mae: 597.0906 - val_loss: 347682.5000 - val_mae: 581.0079\n",
      "Epoch 21/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 312956.3438 - mae: 531.2061 - val_loss: 316872.5625 - val_mae: 554.3124\n",
      "Epoch 22/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 243643.5781 - mae: 442.4765 - val_loss: 288282.3125 - val_mae: 528.3846\n",
      "Epoch 23/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 291011.5312 - mae: 472.9147 - val_loss: 261494.8750 - val_mae: 502.8705\n",
      "Epoch 24/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 178628.7188 - mae: 364.0768 - val_loss: 236732.4062 - val_mae: 478.0690\n",
      "Epoch 25/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 216977.7812 - mae: 435.8407 - val_loss: 213622.5312 - val_mae: 453.6956\n",
      "Epoch 26/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 211302.0938 - mae: 420.7164 - val_loss: 192078.2500 - val_mae: 429.7241\n",
      "Epoch 27/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 201599.8906 - mae: 397.5298 - val_loss: 172204.4688 - val_mae: 406.4429\n",
      "Epoch 28/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 204910.4219 - mae: 394.0853 - val_loss: 153869.3281 - val_mae: 383.7350\n",
      "Epoch 29/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 257471.5469 - mae: 451.7571 - val_loss: 136711.0938 - val_mae: 361.1927\n",
      "Epoch 30/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 102004.2422 - mae: 265.9387 - val_loss: 121267.0000 - val_mae: 339.6226\n",
      "Epoch 31/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 181638.7500 - mae: 390.7206 - val_loss: 107085.5625 - val_mae: 318.5308\n",
      "Epoch 32/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 143890.0781 - mae: 359.0586 - val_loss: 93986.8750 - val_mae: 297.7183\n",
      "Epoch 33/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 110989.0156 - mae: 309.3974 - val_loss: 82200.6094 - val_mae: 277.6536\n",
      "Epoch 34/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 110720.8281 - mae: 304.1300 - val_loss: 71388.8594 - val_mae: 257.8757\n",
      "Epoch 35/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 96539.8516 - mae: 274.5739 - val_loss: 61670.3984 - val_mae: 238.7013\n",
      "Epoch 36/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 79102.3516 - mae: 247.9137 - val_loss: 53076.1133 - val_mae: 220.3587\n",
      "Epoch 37/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 95430.2422 - mae: 262.5294 - val_loss: 45338.6680 - val_mae: 202.4464\n",
      "Epoch 38/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 90444.1875 - mae: 260.6109 - val_loss: 38539.4297 - val_mae: 185.3088\n",
      "Epoch 39/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 62931.0938 - mae: 221.9744 - val_loss: 32573.3965 - val_mae: 168.8452\n",
      "Epoch 40/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 109747.0938 - mae: 261.2610 - val_loss: 27324.4023 - val_mae: 152.9082\n",
      "Epoch 41/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 111050.2109 - mae: 299.1998 - val_loss: 22691.5879 - val_mae: 137.3158\n",
      "Epoch 42/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 82212.2891 - mae: 253.0676 - val_loss: 18716.6250 - val_mae: 122.3736\n",
      "Epoch 43/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 59386.2812 - mae: 186.6516 - val_loss: 15404.6074 - val_mae: 108.3714\n",
      "Epoch 44/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 40612.1523 - mae: 154.2137 - val_loss: 12669.4561 - val_mae: 96.1081\n",
      "Epoch 45/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 72150.9844 - mae: 199.6811 - val_loss: 10410.2285 - val_mae: 88.7116\n",
      "Epoch 46/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 43348.4102 - mae: 169.9384 - val_loss: 8567.9688 - val_mae: 81.7421\n",
      "Epoch 47/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 59136.5469 - mae: 184.3068 - val_loss: 7055.0225 - val_mae: 75.0242\n",
      "Epoch 48/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 38663.6758 - mae: 167.6726 - val_loss: 5896.6191 - val_mae: 68.8747\n",
      "Epoch 49/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 43229.9609 - mae: 155.8039 - val_loss: 4995.7598 - val_mae: 63.0223\n",
      "Epoch 50/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 73186.3203 - mae: 224.9625 - val_loss: 4359.0049 - val_mae: 58.7972\n",
      "Epoch 51/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 44164.4023 - mae: 172.2803 - val_loss: 3886.4526 - val_mae: 57.1428\n",
      "Epoch 52/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 68404.9062 - mae: 210.3650 - val_loss: 3591.2632 - val_mae: 55.6739\n",
      "Epoch 53/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 34465.3867 - mae: 137.3711 - val_loss: 3421.2793 - val_mae: 54.3091\n",
      "Epoch 54/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 31633.4805 - mae: 140.4566 - val_loss: 3354.2688 - val_mae: 53.0539\n",
      "Epoch 55/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 36867.4766 - mae: 153.0247 - val_loss: 3365.2102 - val_mae: 51.9755\n",
      "Epoch 56/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 37597.8828 - mae: 145.0191 - val_loss: 3426.6948 - val_mae: 51.0182\n",
      "Epoch 57/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 51730.2617 - mae: 188.3392 - val_loss: 3512.5872 - val_mae: 50.2438\n",
      "Epoch 58/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 47918.3398 - mae: 186.3144 - val_loss: 3622.3667 - val_mae: 49.5186\n",
      "Epoch 59/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 53321.6641 - mae: 176.7395 - val_loss: 3700.9321 - val_mae: 49.0733\n",
      "Epoch 60/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 65537.8672 - mae: 194.3149 - val_loss: 3758.1226 - val_mae: 48.7582\n",
      "Epoch 61/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 58328.5781 - mae: 177.7631 - val_loss: 3777.9895 - val_mae: 48.6207\n",
      "Epoch 62/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 91912.1719 - mae: 246.8721 - val_loss: 3740.8384 - val_mae: 48.7541\n",
      "Epoch 63/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 24120.0059 - mae: 122.3148 - val_loss: 3702.2075 - val_mae: 48.8972\n",
      "Epoch 64/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 27296.7441 - mae: 121.5243 - val_loss: 3654.3706 - val_mae: 49.0919\n",
      "Epoch 65/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 63111.7422 - mae: 192.5380 - val_loss: 3583.0964 - val_mae: 49.4317\n",
      "Epoch 66/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 46407.5312 - mae: 177.2793 - val_loss: 3514.1172 - val_mae: 49.7896\n",
      "Epoch 67/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 31566.9414 - mae: 136.3394 - val_loss: 3453.2427 - val_mae: 50.1539\n",
      "Epoch 68/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 41443.2383 - mae: 147.4131 - val_loss: 3391.7944 - val_mae: 50.6220\n",
      "Epoch 69/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 33883.0273 - mae: 126.8692 - val_loss: 3341.7593 - val_mae: 51.1365\n",
      "Epoch 70/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 38561.7656 - mae: 152.2111 - val_loss: 3309.7273 - val_mae: 51.6363\n",
      "Epoch 71/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 78263.3047 - mae: 224.1587 - val_loss: 3292.9390 - val_mae: 52.2293\n",
      "Epoch 72/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 46031.2578 - mae: 169.8466 - val_loss: 3299.4153 - val_mae: 52.9045\n",
      "Epoch 73/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 23011.9023 - mae: 114.4944 - val_loss: 3327.0957 - val_mae: 53.4896\n",
      "Epoch 74/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 58958.7617 - mae: 192.6891 - val_loss: 3378.0332 - val_mae: 54.1022\n",
      "Epoch 75/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 38247.9688 - mae: 131.7804 - val_loss: 3439.4993 - val_mae: 54.6240\n",
      "Epoch 76/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 48075.9688 - mae: 156.3827 - val_loss: 3538.6667 - val_mae: 55.2723\n",
      "Epoch 77/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 56389.7578 - mae: 191.6278 - val_loss: 3656.4211 - val_mae: 55.8866\n",
      "Epoch 78/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 53803.0078 - mae: 178.9408 - val_loss: 3803.7104 - val_mae: 56.5284\n",
      "Epoch 79/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 32770.6523 - mae: 148.6723 - val_loss: 3939.6440 - val_mae: 57.0362\n",
      "Epoch 80/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 35580.8867 - mae: 156.0250 - val_loss: 4051.9421 - val_mae: 57.4156\n",
      "Epoch 81/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 73124.6875 - mae: 211.3854 - val_loss: 4174.0498 - val_mae: 57.8028\n",
      "Epoch 82/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 26674.8848 - mae: 133.6089 - val_loss: 4285.3623 - val_mae: 58.1331\n",
      "Epoch 83/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 26609.1074 - mae: 126.9600 - val_loss: 4407.6372 - val_mae: 58.4749\n",
      "Epoch 84/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 39591.8828 - mae: 163.6949 - val_loss: 4455.2935 - val_mae: 58.8302\n",
      "Epoch 85/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 61466.5391 - mae: 204.1437 - val_loss: 4492.5010 - val_mae: 59.1381\n",
      "Epoch 86/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 47549.4180 - mae: 164.9488 - val_loss: 4506.9717 - val_mae: 59.2490\n",
      "Epoch 87/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 46781.9648 - mae: 160.6933 - val_loss: 4544.4868 - val_mae: 59.5411\n",
      "Epoch 88/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 25646.3906 - mae: 124.4900 - val_loss: 4596.3350 - val_mae: 59.9429\n",
      "Epoch 89/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 47640.2148 - mae: 183.5024 - val_loss: 4653.2388 - val_mae: 60.3794\n",
      "Epoch 90/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 40134.5703 - mae: 158.7442 - val_loss: 4690.0923 - val_mae: 60.6472\n",
      "Epoch 91/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 62666.7031 - mae: 213.3754 - val_loss: 4729.7192 - val_mae: 60.9359\n",
      "Epoch 92/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 72795.3047 - mae: 218.4471 - val_loss: 4761.7920 - val_mae: 61.1647\n",
      "Epoch 93/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 41992.2188 - mae: 163.0213 - val_loss: 4812.9863 - val_mae: 61.5408\n",
      "Epoch 94/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 31020.7930 - mae: 134.0578 - val_loss: 4819.5361 - val_mae: 61.5827\n",
      "Epoch 95/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 53374.3281 - mae: 194.3371 - val_loss: 4798.0825 - val_mae: 61.4131\n",
      "Epoch 96/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 26155.5078 - mae: 133.8037 - val_loss: 4758.6621 - val_mae: 61.1023\n",
      "Epoch 97/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 45711.7773 - mae: 190.8952 - val_loss: 4755.1772 - val_mae: 61.0607\n",
      "Epoch 98/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 25747.5312 - mae: 124.7119 - val_loss: 4710.0522 - val_mae: 60.7023\n",
      "Epoch 99/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 32123.0254 - mae: 145.0361 - val_loss: 4680.1152 - val_mae: 60.4560\n",
      "Epoch 100/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 57024.2305 - mae: 203.0738 - val_loss: 4594.9111 - val_mae: 59.7617\n",
      "Epoch 101/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 42040.8672 - mae: 147.1025 - val_loss: 4537.2583 - val_mae: 59.2759\n",
      "Epoch 102/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 74360.2422 - mae: 228.8778 - val_loss: 4481.4561 - val_mae: 58.8375\n",
      "Epoch 103/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 26120.6719 - mae: 136.2043 - val_loss: 4418.1426 - val_mae: 58.6679\n",
      "Epoch 104/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 81843.2656 - mae: 240.1426 - val_loss: 4260.5688 - val_mae: 58.2172\n",
      "Epoch 105/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 42411.7383 - mae: 174.8658 - val_loss: 4079.2883 - val_mae: 57.6505\n",
      "Epoch 106/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 29346.7402 - mae: 145.4741 - val_loss: 3921.4526 - val_mae: 57.1032\n",
      "Epoch 107/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 42778.2812 - mae: 163.1383 - val_loss: 3805.0879 - val_mae: 56.6619\n",
      "Epoch 108/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 35366.6016 - mae: 156.7230 - val_loss: 3713.8684 - val_mae: 56.2794\n",
      "Epoch 109/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 41695.3828 - mae: 173.7169 - val_loss: 3621.2974 - val_mae: 55.8458\n",
      "Epoch 110/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 56153.0859 - mae: 207.0269 - val_loss: 3552.3457 - val_mae: 55.4870\n",
      "Epoch 111/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 39234.2734 - mae: 153.1521 - val_loss: 3502.0554 - val_mae: 55.1977\n",
      "Epoch 112/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 29217.0625 - mae: 135.4642 - val_loss: 3455.7097 - val_mae: 54.9072\n",
      "Epoch 113/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 23114.5664 - mae: 121.8312 - val_loss: 3431.8040 - val_mae: 54.7462\n",
      "Epoch 114/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 44554.5234 - mae: 151.3011 - val_loss: 3419.3755 - val_mae: 54.6612\n",
      "Epoch 115/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 24777.1875 - mae: 121.9563 - val_loss: 3392.6587 - val_mae: 54.4674\n",
      "Epoch 116/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 18052.6641 - mae: 106.2578 - val_loss: 3375.5476 - val_mae: 54.3366\n",
      "Epoch 117/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 60495.2188 - mae: 192.4964 - val_loss: 3368.6355 - val_mae: 54.2848\n",
      "Epoch 118/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 44866.1133 - mae: 164.8704 - val_loss: 3368.2603 - val_mae: 54.2867\n",
      "Epoch 119/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 28568.2402 - mae: 139.8526 - val_loss: 3378.8477 - val_mae: 54.3725\n",
      "Epoch 120/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 51220.3164 - mae: 185.7124 - val_loss: 3389.9004 - val_mae: 54.4561\n",
      "Epoch 121/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 45062.2930 - mae: 176.2940 - val_loss: 3419.9888 - val_mae: 54.6704\n",
      "Epoch 122/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 42496.6797 - mae: 161.5988 - val_loss: 3474.1387 - val_mae: 55.0122\n",
      "Epoch 123/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - loss: 56166.2969 - mae: 209.6814 - val_loss: 3527.4785 - val_mae: 55.3110\n",
      "Epoch 124/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 32823.2227 - mae: 132.0501 - val_loss: 3572.0835 - val_mae: 55.5367\n",
      "Epoch 125/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 22373.9570 - mae: 108.6896 - val_loss: 3619.2903 - val_mae: 55.7573\n",
      "Epoch 126/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 45641.0781 - mae: 154.2142 - val_loss: 3660.7122 - val_mae: 55.9396\n",
      "Epoch 127/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 40645.4336 - mae: 155.6441 - val_loss: 3694.4543 - val_mae: 56.0808\n",
      "Epoch 128/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 62061.0195 - mae: 211.2425 - val_loss: 3732.3281 - val_mae: 56.2350\n",
      "Epoch 129/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 68292.2031 - mae: 190.5693 - val_loss: 3751.6609 - val_mae: 56.3112\n",
      "Epoch 130/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 63223.5977 - mae: 207.9834 - val_loss: 3719.5925 - val_mae: 56.1821\n",
      "Epoch 131/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - loss: 50401.8516 - mae: 174.5888 - val_loss: 3696.4419 - val_mae: 56.0835\n",
      "Epoch 132/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 25847.6191 - mae: 117.1452 - val_loss: 3688.2922 - val_mae: 56.0523\n",
      "Epoch 133/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 42701.1758 - mae: 164.6271 - val_loss: 3664.3184 - val_mae: 55.9489\n",
      "Epoch 134/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 58176.5117 - mae: 172.2536 - val_loss: 3601.3921 - val_mae: 55.6586\n",
      "Epoch 135/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 27205.5137 - mae: 143.3781 - val_loss: 3526.7117 - val_mae: 55.2845\n",
      "Epoch 136/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 42303.3672 - mae: 138.7579 - val_loss: 3450.9702 - val_mae: 54.8610\n",
      "Epoch 137/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 50514.9648 - mae: 183.1333 - val_loss: 3405.0613 - val_mae: 54.5728\n",
      "Epoch 138/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 34747.5234 - mae: 129.5601 - val_loss: 3379.9128 - val_mae: 54.4030\n",
      "Epoch 139/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 45140.5859 - mae: 160.9802 - val_loss: 3355.8140 - val_mae: 54.2296\n",
      "Epoch 140/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 19956.3105 - mae: 111.8934 - val_loss: 3328.5886 - val_mae: 54.0168\n",
      "Epoch 141/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 36860.8672 - mae: 147.9569 - val_loss: 3309.8118 - val_mae: 53.8562\n",
      "Epoch 142/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 34518.3984 - mae: 143.6106 - val_loss: 3299.7605 - val_mae: 53.7684\n",
      "Epoch 143/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 19834.5059 - mae: 117.4801 - val_loss: 3280.9243 - val_mae: 53.5882\n",
      "Epoch 144/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 23649.1699 - mae: 133.5643 - val_loss: 3257.1760 - val_mae: 53.3319\n",
      "Epoch 145/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6710.6372 - mae: 62.7692 - val_loss: 3236.9924 - val_mae: 53.0792\n",
      "Epoch 146/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 34044.0859 - mae: 149.5181 - val_loss: 3224.3406 - val_mae: 52.8982\n",
      "Epoch 147/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 22894.9590 - mae: 127.8059 - val_loss: 3215.7712 - val_mae: 52.7622\n",
      "Epoch 148/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 42921.4570 - mae: 175.9155 - val_loss: 3206.9080 - val_mae: 52.5952\n",
      "Epoch 149/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 29007.6250 - mae: 124.7464 - val_loss: 3198.9038 - val_mae: 52.4040\n",
      "Epoch 150/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 50409.5938 - mae: 191.2018 - val_loss: 3191.8713 - val_mae: 52.1202\n",
      "Epoch 151/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 28084.5469 - mae: 142.7624 - val_loss: 3190.2964 - val_mae: 51.8243\n",
      "Epoch 152/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 42417.8203 - mae: 173.2657 - val_loss: 3192.6089 - val_mae: 51.5697\n",
      "Epoch 153/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 34891.1016 - mae: 156.6922 - val_loss: 3195.7095 - val_mae: 51.3772\n",
      "Epoch 154/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 30378.1777 - mae: 129.8067 - val_loss: 3197.9878 - val_mae: 51.2788\n",
      "Epoch 155/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 45811.2422 - mae: 171.1299 - val_loss: 3199.0220 - val_mae: 51.2144\n",
      "Epoch 156/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 20053.1504 - mae: 114.9854 - val_loss: 3202.6929 - val_mae: 51.0903\n",
      "Epoch 157/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 21454.4316 - mae: 122.4872 - val_loss: 3205.1367 - val_mae: 51.0110\n",
      "Epoch 158/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 75200.0625 - mae: 232.6665 - val_loss: 3209.3535 - val_mae: 50.8376\n",
      "Epoch 159/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 45225.1797 - mae: 169.8435 - val_loss: 3222.7654 - val_mae: 50.5422\n",
      "Epoch 160/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 36897.4727 - mae: 155.7665 - val_loss: 3240.8218 - val_mae: 50.2285\n",
      "Epoch 161/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 30942.7070 - mae: 135.6087 - val_loss: 3269.8684 - val_mae: 49.8419\n",
      "Epoch 162/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 32461.1719 - mae: 126.5253 - val_loss: 3301.7649 - val_mae: 49.4792\n",
      "Epoch 163/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 50310.4453 - mae: 173.5706 - val_loss: 3320.7739 - val_mae: 49.2417\n",
      "Epoch 164/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - loss: 35183.2344 - mae: 139.7881 - val_loss: 3350.4414 - val_mae: 48.9505\n",
      "Epoch 165/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 28839.4531 - mae: 127.1881 - val_loss: 3385.3105 - val_mae: 48.6635\n",
      "Epoch 166/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 40480.3555 - mae: 167.8002 - val_loss: 3399.8911 - val_mae: 48.5174\n",
      "Epoch 167/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 31322.8457 - mae: 148.3225 - val_loss: 3404.3860 - val_mae: 48.4463\n",
      "Epoch 168/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 40839.2891 - mae: 165.0061 - val_loss: 3397.5229 - val_mae: 48.4386\n",
      "Epoch 169/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 39483.0000 - mae: 152.7330 - val_loss: 3362.4094 - val_mae: 48.6149\n",
      "Epoch 170/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 22089.0469 - mae: 109.0097 - val_loss: 3329.4761 - val_mae: 48.7877\n",
      "Epoch 171/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 54367.8086 - mae: 182.4531 - val_loss: 3276.4915 - val_mae: 49.1178\n",
      "Epoch 172/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 31775.5566 - mae: 159.5835 - val_loss: 3233.9124 - val_mae: 49.4193\n",
      "Epoch 173/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 38026.0195 - mae: 153.0240 - val_loss: 3186.4050 - val_mae: 49.8448\n",
      "Epoch 174/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 16862.3594 - mae: 91.1490 - val_loss: 3148.4658 - val_mae: 50.3177\n",
      "Epoch 175/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 71120.0781 - mae: 218.9823 - val_loss: 3123.6274 - val_mae: 50.7873\n",
      "Epoch 176/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 13837.0312 - mae: 89.5000 - val_loss: 3113.7607 - val_mae: 51.2593\n",
      "Epoch 177/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 40204.5625 - mae: 167.3009 - val_loss: 3118.8779 - val_mae: 51.7268\n",
      "Epoch 178/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 45884.0195 - mae: 182.9947 - val_loss: 3134.4136 - val_mae: 52.1230\n",
      "Epoch 179/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 20857.2090 - mae: 99.4644 - val_loss: 3152.2178 - val_mae: 52.4135\n",
      "Epoch 180/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 26416.3008 - mae: 123.6450 - val_loss: 3180.1831 - val_mae: 52.7508\n",
      "Epoch 181/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13929.3154 - mae: 95.0536 - val_loss: 3203.3660 - val_mae: 52.9791\n",
      "Epoch 182/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 32904.1367 - mae: 156.0249 - val_loss: 3229.1782 - val_mae: 53.1987\n",
      "Epoch 183/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 18234.6621 - mae: 101.4396 - val_loss: 3261.9199 - val_mae: 53.4454\n",
      "Epoch 184/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 19889.8281 - mae: 111.2815 - val_loss: 3303.2710 - val_mae: 53.7244\n",
      "Epoch 185/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 34689.6133 - mae: 161.8694 - val_loss: 3346.1040 - val_mae: 53.9830\n",
      "Epoch 186/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 52359.0742 - mae: 181.1664 - val_loss: 3375.3403 - val_mae: 54.1454\n",
      "Epoch 187/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 40400.1602 - mae: 163.7573 - val_loss: 3359.3965 - val_mae: 54.0536\n",
      "Epoch 188/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 21497.5820 - mae: 122.5230 - val_loss: 3338.3950 - val_mae: 53.9314\n",
      "Epoch 189/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 30493.5762 - mae: 138.5964 - val_loss: 3307.2122 - val_mae: 53.7396\n",
      "Epoch 190/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 23869.4121 - mae: 113.3210 - val_loss: 3275.0278 - val_mae: 53.5288\n",
      "Epoch 191/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 51829.6562 - mae: 184.3642 - val_loss: 3266.3848 - val_mae: 53.4697\n",
      "Epoch 192/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 30944.0527 - mae: 139.4190 - val_loss: 3245.9226 - val_mae: 53.3251\n",
      "Epoch 193/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 21547.8223 - mae: 115.3729 - val_loss: 3229.0857 - val_mae: 53.2011\n",
      "Epoch 194/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 40577.9453 - mae: 160.8287 - val_loss: 3202.1440 - val_mae: 52.9907\n",
      "Epoch 195/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 47114.2383 - mae: 185.7328 - val_loss: 3204.1304 - val_mae: 53.0070\n",
      "Epoch 196/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 21639.9375 - mae: 119.2952 - val_loss: 3191.3530 - val_mae: 52.9020\n",
      "Epoch 197/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 19963.5039 - mae: 103.9706 - val_loss: 3177.0540 - val_mae: 52.7808\n",
      "Epoch 198/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 32696.8418 - mae: 129.5354 - val_loss: 3166.0142 - val_mae: 52.6835\n",
      "Epoch 199/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 30817.2207 - mae: 144.2866 - val_loss: 3164.4126 - val_mae: 52.6695\n",
      "Epoch 200/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 29439.9512 - mae: 143.4678 - val_loss: 3165.5266 - val_mae: 52.6795\n",
      "Epoch 201/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 17839.1426 - mae: 106.0182 - val_loss: 3169.0522 - val_mae: 52.7101\n",
      "Epoch 202/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 15185.4014 - mae: 106.0768 - val_loss: 3166.7578 - val_mae: 52.6894\n",
      "Epoch 203/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 22942.6191 - mae: 120.0673 - val_loss: 3163.9753 - val_mae: 52.6648\n",
      "Epoch 204/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 19143.8672 - mae: 115.7404 - val_loss: 3163.6558 - val_mae: 52.6609\n",
      "Epoch 205/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 28320.5098 - mae: 129.9250 - val_loss: 3172.5513 - val_mae: 52.7343\n",
      "Epoch 206/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 27846.9609 - mae: 134.9166 - val_loss: 3165.4556 - val_mae: 52.6747\n",
      "Epoch 207/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 24764.1699 - mae: 124.1359 - val_loss: 3167.8953 - val_mae: 52.6919\n",
      "Epoch 208/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 22428.6836 - mae: 125.0383 - val_loss: 3164.3140 - val_mae: 52.6605\n",
      "Epoch 209/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 47901.7617 - mae: 176.8519 - val_loss: 3171.9473 - val_mae: 52.7205\n",
      "Epoch 210/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 26234.6992 - mae: 120.8814 - val_loss: 3168.7153 - val_mae: 52.7027\n",
      "Epoch 211/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 38524.1797 - mae: 157.9708 - val_loss: 3180.8462 - val_mae: 52.8004\n",
      "Epoch 212/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 28627.0195 - mae: 140.1356 - val_loss: 3176.6372 - val_mae: 52.7769\n",
      "Epoch 213/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 48289.2227 - mae: 167.2591 - val_loss: 3159.2271 - val_mae: 52.6546\n",
      "Epoch 214/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 32199.2637 - mae: 150.1757 - val_loss: 3157.5085 - val_mae: 52.6321\n",
      "Epoch 215/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 19811.2480 - mae: 126.3633 - val_loss: 3154.7456 - val_mae: 52.6010\n",
      "Epoch 216/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 33367.7109 - mae: 144.7799 - val_loss: 3168.0571 - val_mae: 52.6807\n",
      "Epoch 217/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 19079.7031 - mae: 110.7461 - val_loss: 3180.4312 - val_mae: 52.7426\n",
      "Epoch 218/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 43856.3398 - mae: 165.1888 - val_loss: 3176.5071 - val_mae: 52.6870\n",
      "Epoch 219/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 30754.8809 - mae: 145.1821 - val_loss: 3164.4062 - val_mae: 52.5755\n",
      "Epoch 220/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 18798.9746 - mae: 109.4529 - val_loss: 3146.8076 - val_mae: 52.4252\n",
      "Epoch 221/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 22823.1680 - mae: 137.7215 - val_loss: 3114.2007 - val_mae: 52.1686\n",
      "Epoch 222/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 17367.6680 - mae: 108.0830 - val_loss: 3072.5344 - val_mae: 51.8384\n",
      "Epoch 223/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 18447.0234 - mae: 110.2431 - val_loss: 3043.6289 - val_mae: 51.5967\n",
      "Epoch 224/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 20236.6582 - mae: 101.0652 - val_loss: 3028.8264 - val_mae: 51.4627\n",
      "Epoch 225/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 24296.8906 - mae: 127.8354 - val_loss: 3016.5142 - val_mae: 51.3465\n",
      "Epoch 226/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 26174.2383 - mae: 128.1658 - val_loss: 3001.4775 - val_mae: 51.2074\n",
      "Epoch 227/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 30053.4668 - mae: 138.7727 - val_loss: 2967.4412 - val_mae: 50.9158\n",
      "Epoch 228/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10007.4873 - mae: 82.8625 - val_loss: 2948.4531 - val_mae: 50.7421\n",
      "Epoch 229/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - loss: 32023.6836 - mae: 151.7056 - val_loss: 2934.7712 - val_mae: 50.6157\n",
      "Epoch 230/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 17282.7246 - mae: 102.7486 - val_loss: 2924.9038 - val_mae: 50.5224\n",
      "Epoch 231/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 35486.3711 - mae: 141.8795 - val_loss: 2936.8350 - val_mae: 50.6103\n",
      "Epoch 232/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 15376.6201 - mae: 106.0484 - val_loss: 2953.7886 - val_mae: 50.7309\n",
      "Epoch 233/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 24323.6777 - mae: 118.2698 - val_loss: 2970.9380 - val_mae: 50.8442\n",
      "Epoch 234/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 20855.9902 - mae: 119.4390 - val_loss: 2992.8972 - val_mae: 50.9899\n",
      "Epoch 235/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 25184.7305 - mae: 129.7346 - val_loss: 3029.8127 - val_mae: 51.2184\n",
      "Epoch 236/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 26786.5156 - mae: 139.1183 - val_loss: 3066.2397 - val_mae: 51.4200\n",
      "Epoch 237/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 27628.0137 - mae: 139.2945 - val_loss: 3082.2297 - val_mae: 51.4803\n",
      "Epoch 238/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 27719.0996 - mae: 134.2924 - val_loss: 3110.9089 - val_mae: 51.5990\n",
      "Epoch 239/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 19188.0156 - mae: 116.5537 - val_loss: 3157.7251 - val_mae: 51.8172\n",
      "Epoch 240/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 30244.1406 - mae: 143.0530 - val_loss: 3179.0801 - val_mae: 51.8753\n",
      "Epoch 241/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 31475.9531 - mae: 125.5403 - val_loss: 3185.9731 - val_mae: 51.8565\n",
      "Epoch 242/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 14073.9453 - mae: 93.5871 - val_loss: 3179.9370 - val_mae: 51.7808\n",
      "Epoch 243/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 21814.2012 - mae: 118.7095 - val_loss: 3158.2781 - val_mae: 51.6252\n",
      "Epoch 244/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 16650.2461 - mae: 97.6820 - val_loss: 3128.0610 - val_mae: 51.4316\n",
      "Epoch 245/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 34751.0000 - mae: 144.5058 - val_loss: 3105.7441 - val_mae: 51.2693\n",
      "Epoch 246/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 22323.9902 - mae: 120.6244 - val_loss: 3063.6606 - val_mae: 51.0046\n",
      "Epoch 247/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 24816.3379 - mae: 129.1186 - val_loss: 3019.6692 - val_mae: 50.7227\n",
      "Epoch 248/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 28588.4512 - mae: 139.4454 - val_loss: 2962.3350 - val_mae: 50.3605\n",
      "Epoch 249/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 22594.3184 - mae: 123.8486 - val_loss: 2879.5522 - val_mae: 49.8107\n",
      "Epoch 250/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 33086.4688 - mae: 141.5336 - val_loss: 2810.4009 - val_mae: 49.3098\n",
      "Epoch 251/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 22111.9570 - mae: 114.0396 - val_loss: 2769.2998 - val_mae: 48.9857\n",
      "Epoch 252/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 21999.1738 - mae: 101.4775 - val_loss: 2737.2878 - val_mae: 48.7163\n",
      "Epoch 253/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 14259.1904 - mae: 93.8814 - val_loss: 2710.5552 - val_mae: 48.4746\n",
      "Epoch 254/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 25933.2715 - mae: 129.4408 - val_loss: 2678.4360 - val_mae: 48.1563\n",
      "Epoch 255/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 24551.9883 - mae: 121.8640 - val_loss: 2653.3987 - val_mae: 47.8829\n",
      "Epoch 256/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 30894.2461 - mae: 148.5373 - val_loss: 2633.4053 - val_mae: 47.6475\n",
      "Epoch 257/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 21940.7988 - mae: 127.2326 - val_loss: 2623.6130 - val_mae: 47.5324\n",
      "Epoch 258/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 18482.0000 - mae: 108.1817 - val_loss: 2606.9731 - val_mae: 47.3217\n",
      "Epoch 259/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 28823.4043 - mae: 137.2296 - val_loss: 2592.5605 - val_mae: 47.1305\n",
      "Epoch 260/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 31220.6582 - mae: 139.1372 - val_loss: 2588.8569 - val_mae: 47.1003\n",
      "Epoch 261/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 35028.6484 - mae: 144.0297 - val_loss: 2588.8826 - val_mae: 47.1197\n",
      "Epoch 262/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - loss: 13300.2148 - mae: 94.3919 - val_loss: 2592.5872 - val_mae: 47.1995\n",
      "Epoch 263/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 22593.0234 - mae: 117.7969 - val_loss: 2591.9058 - val_mae: 47.2141\n",
      "Epoch 264/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 20984.7246 - mae: 123.5690 - val_loss: 2587.1018 - val_mae: 47.1659\n",
      "Epoch 265/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 17407.1113 - mae: 108.2614 - val_loss: 2581.3413 - val_mae: 47.1043\n",
      "Epoch 266/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 29465.1914 - mae: 141.3702 - val_loss: 2580.1909 - val_mae: 47.1116\n",
      "Epoch 267/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 16343.6279 - mae: 100.3939 - val_loss: 2576.3091 - val_mae: 47.0776\n",
      "Epoch 268/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 34904.3867 - mae: 153.5158 - val_loss: 2578.6526 - val_mae: 47.1261\n",
      "Epoch 269/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 12522.4580 - mae: 84.6291 - val_loss: 2584.1851 - val_mae: 47.2073\n",
      "Epoch 270/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 22760.2441 - mae: 102.2282 - val_loss: 2582.5176 - val_mae: 47.1998\n",
      "Epoch 271/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 28384.7168 - mae: 141.6003 - val_loss: 2585.4036 - val_mae: 47.2352\n",
      "Epoch 272/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 11525.9883 - mae: 86.7220 - val_loss: 2584.0425 - val_mae: 47.2208\n",
      "Epoch 273/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - loss: 28772.8691 - mae: 142.4661 - val_loss: 2589.5398 - val_mae: 47.2720\n",
      "Epoch 274/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 31498.0723 - mae: 141.9277 - val_loss: 2600.1028 - val_mae: 47.3583\n",
      "Epoch 275/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 16963.4727 - mae: 97.4426 - val_loss: 2601.7312 - val_mae: 47.3551\n",
      "Epoch 276/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 25068.6992 - mae: 129.0828 - val_loss: 2589.8677 - val_mae: 47.2325\n",
      "Epoch 277/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 35195.7188 - mae: 154.0103 - val_loss: 2584.9797 - val_mae: 47.1689\n",
      "Epoch 278/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 26150.5488 - mae: 115.6827 - val_loss: 2565.0298 - val_mae: 46.9739\n",
      "Epoch 279/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 18982.9199 - mae: 114.6268 - val_loss: 2542.7927 - val_mae: 46.7580\n",
      "Epoch 280/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 17200.0117 - mae: 105.3795 - val_loss: 2525.3901 - val_mae: 46.5811\n",
      "Epoch 281/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 15793.6104 - mae: 109.0581 - val_loss: 2507.6672 - val_mae: 46.4032\n",
      "Epoch 282/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 20765.5664 - mae: 123.3924 - val_loss: 2507.5337 - val_mae: 46.3857\n",
      "Epoch 283/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 39872.4023 - mae: 172.6527 - val_loss: 2503.9380 - val_mae: 46.3365\n",
      "Epoch 284/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - loss: 23880.2148 - mae: 119.9013 - val_loss: 2500.4341 - val_mae: 46.2892\n",
      "Epoch 285/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 5589.1821 - mae: 61.8326 - val_loss: 2502.1284 - val_mae: 46.2886\n",
      "Epoch 286/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 20019.9844 - mae: 107.1681 - val_loss: 2508.7639 - val_mae: 46.3247\n",
      "Epoch 287/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 26312.6309 - mae: 131.5552 - val_loss: 2515.2695 - val_mae: 46.3565\n",
      "Epoch 288/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 35408.0117 - mae: 158.3669 - val_loss: 2516.3215 - val_mae: 46.3287\n",
      "Epoch 289/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 25764.0879 - mae: 134.1047 - val_loss: 2529.8320 - val_mae: 46.3906\n",
      "Epoch 290/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 18685.4062 - mae: 109.7168 - val_loss: 2547.7295 - val_mae: 46.4734\n",
      "Epoch 291/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 34386.5000 - mae: 154.1451 - val_loss: 2559.4097 - val_mae: 46.4961\n",
      "Epoch 292/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13068.1416 - mae: 93.0005 - val_loss: 2561.8875 - val_mae: 46.4506\n",
      "Epoch 293/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 37776.3008 - mae: 161.4912 - val_loss: 2566.4651 - val_mae: 46.4148\n",
      "Epoch 294/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 21387.3047 - mae: 112.4337 - val_loss: 2568.5083 - val_mae: 46.3557\n",
      "Epoch 295/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 22359.3535 - mae: 124.7154 - val_loss: 2563.1924 - val_mae: 46.2532\n",
      "Epoch 296/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 9391.2139 - mae: 83.6446 - val_loss: 2552.9902 - val_mae: 46.1286\n",
      "Epoch 297/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 25454.9844 - mae: 130.7375 - val_loss: 2542.2043 - val_mae: 45.9962\n",
      "Epoch 298/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 22556.4785 - mae: 131.6044 - val_loss: 2520.1274 - val_mae: 45.7934\n",
      "Epoch 299/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 33786.5312 - mae: 136.5086 - val_loss: 2501.6255 - val_mae: 45.6122\n",
      "Epoch 300/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 18410.0527 - mae: 111.6063 - val_loss: 2498.2393 - val_mae: 45.5186\n",
      "Epoch 301/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 23377.0215 - mae: 115.7358 - val_loss: 2493.7437 - val_mae: 45.4108\n",
      "Epoch 302/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 14893.1582 - mae: 90.1954 - val_loss: 2469.8552 - val_mae: 45.1813\n",
      "Epoch 303/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 25233.8730 - mae: 122.9415 - val_loss: 2444.7244 - val_mae: 44.9354\n",
      "Epoch 304/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 28526.9863 - mae: 137.7880 - val_loss: 2454.9495 - val_mae: 44.9008\n",
      "Epoch 305/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 16716.1816 - mae: 100.8327 - val_loss: 2459.2603 - val_mae: 44.8228\n",
      "Epoch 306/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8166.1455 - mae: 62.7250 - val_loss: 2464.2170 - val_mae: 44.7613\n",
      "Epoch 307/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 19204.0918 - mae: 117.5009 - val_loss: 2456.1870 - val_mae: 44.6292\n",
      "Epoch 308/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - loss: 18321.0293 - mae: 109.3956 - val_loss: 2426.9399 - val_mae: 44.3750\n",
      "Epoch 309/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 12874.1094 - mae: 88.7217 - val_loss: 2382.7637 - val_mae: 44.0368\n",
      "Epoch 310/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13231.7393 - mae: 83.0773 - val_loss: 2350.4294 - val_mae: 43.7570\n",
      "Epoch 311/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 19682.1230 - mae: 113.2254 - val_loss: 2309.9766 - val_mae: 43.4305\n",
      "Epoch 312/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 14429.2695 - mae: 99.2364 - val_loss: 2260.7573 - val_mae: 43.0396\n",
      "Epoch 313/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 19121.6582 - mae: 99.0267 - val_loss: 2206.5894 - val_mae: 42.6014\n",
      "Epoch 314/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 18656.0449 - mae: 105.4086 - val_loss: 2171.0078 - val_mae: 42.2754\n",
      "Epoch 315/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 15120.0459 - mae: 98.1354 - val_loss: 2135.5327 - val_mae: 41.9460\n",
      "Epoch 316/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 16096.9082 - mae: 101.1078 - val_loss: 2109.1155 - val_mae: 41.6758\n",
      "Epoch 317/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 19502.7285 - mae: 103.5645 - val_loss: 2076.2642 - val_mae: 41.3538\n",
      "Epoch 318/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 23146.3398 - mae: 117.9951 - val_loss: 2059.0212 - val_mae: 41.1443\n",
      "Epoch 319/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 17795.6309 - mae: 101.9769 - val_loss: 2055.6118 - val_mae: 41.0440\n",
      "Epoch 320/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 28043.7207 - mae: 132.2799 - val_loss: 2064.1245 - val_mae: 41.0267\n",
      "Epoch 321/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 15168.2744 - mae: 104.2062 - val_loss: 2077.3984 - val_mae: 41.0315\n",
      "Epoch 322/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 24855.7305 - mae: 141.6231 - val_loss: 2085.1960 - val_mae: 40.9977\n",
      "Epoch 323/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 13285.9736 - mae: 94.3967 - val_loss: 2085.9370 - val_mae: 40.9128\n",
      "Epoch 324/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 19730.3203 - mae: 115.9202 - val_loss: 2079.6216 - val_mae: 40.7779\n",
      "Epoch 325/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8742.9590 - mae: 74.1808 - val_loss: 2055.8108 - val_mae: 40.5354\n",
      "Epoch 326/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6540.1641 - mae: 61.2109 - val_loss: 2043.1055 - val_mae: 40.3659\n",
      "Epoch 327/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 13702.0020 - mae: 93.4896 - val_loss: 2021.7018 - val_mae: 40.1405\n",
      "Epoch 328/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 17781.9629 - mae: 110.0424 - val_loss: 1995.3730 - val_mae: 39.8882\n",
      "Epoch 329/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 16047.3252 - mae: 111.1573 - val_loss: 1986.6663 - val_mae: 39.7518\n",
      "Epoch 330/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 17722.1602 - mae: 97.8261 - val_loss: 1973.2582 - val_mae: 39.5832\n",
      "Epoch 331/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 25622.5859 - mae: 130.4964 - val_loss: 1973.7209 - val_mae: 39.5066\n",
      "Epoch 332/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 15788.9141 - mae: 92.1965 - val_loss: 1987.1276 - val_mae: 39.5152\n",
      "Epoch 333/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 10844.8096 - mae: 81.5235 - val_loss: 2005.5488 - val_mae: 39.5624\n",
      "Epoch 334/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 8834.9961 - mae: 74.6744 - val_loss: 2036.0492 - val_mae: 39.6927\n",
      "Epoch 335/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 19025.9531 - mae: 111.7975 - val_loss: 2038.1295 - val_mae: 39.6474\n",
      "Epoch 336/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 16603.6328 - mae: 89.7156 - val_loss: 2031.6663 - val_mae: 39.5580\n",
      "Epoch 337/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9456.3633 - mae: 75.4131 - val_loss: 2040.3649 - val_mae: 39.5621\n",
      "Epoch 338/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 15337.9082 - mae: 103.6853 - val_loss: 2056.6633 - val_mae: 39.7049\n",
      "Epoch 339/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 14718.6172 - mae: 101.2341 - val_loss: 2063.2368 - val_mae: 39.8440\n",
      "Epoch 340/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 12353.4502 - mae: 81.0720 - val_loss: 2046.8297 - val_mae: 39.6678\n",
      "Epoch 341/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 15400.3818 - mae: 104.9959 - val_loss: 2014.4358 - val_mae: 39.2655\n",
      "Epoch 342/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9768.2910 - mae: 85.4615 - val_loss: 1958.1559 - val_mae: 38.8230\n",
      "Epoch 343/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 12489.0791 - mae: 85.3551 - val_loss: 1887.1423 - val_mae: 38.3386\n",
      "Epoch 344/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 13303.6846 - mae: 95.2822 - val_loss: 1829.4678 - val_mae: 37.9112\n",
      "Epoch 345/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 16484.3320 - mae: 91.4203 - val_loss: 1780.7416 - val_mae: 37.5174\n",
      "Epoch 346/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 13168.4219 - mae: 85.8954 - val_loss: 1728.8193 - val_mae: 37.0692\n",
      "Epoch 347/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 6302.2607 - mae: 67.3367 - val_loss: 1672.6423 - val_mae: 36.5461\n",
      "Epoch 348/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10448.0527 - mae: 85.6632 - val_loss: 1624.8734 - val_mae: 36.0483\n",
      "Epoch 349/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 15815.7090 - mae: 95.4387 - val_loss: 1577.2562 - val_mae: 35.4759\n",
      "Epoch 350/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 14982.9277 - mae: 92.0512 - val_loss: 1544.3796 - val_mae: 35.0111\n",
      "Epoch 351/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 11109.6670 - mae: 91.0757 - val_loss: 1523.5486 - val_mae: 34.6840\n",
      "Epoch 352/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5684.9829 - mae: 59.9337 - val_loss: 1504.0929 - val_mae: 34.3476\n",
      "Epoch 353/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 19151.7539 - mae: 101.9798 - val_loss: 1487.6477 - val_mae: 34.0357\n",
      "Epoch 354/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 17569.2129 - mae: 104.3716 - val_loss: 1471.3966 - val_mae: 33.7037\n",
      "Epoch 355/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8521.5957 - mae: 72.2665 - val_loss: 1458.1150 - val_mae: 33.4218\n",
      "Epoch 356/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 11085.9863 - mae: 81.6329 - val_loss: 1449.7672 - val_mae: 33.3015\n",
      "Epoch 357/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 14989.6641 - mae: 98.7117 - val_loss: 1441.2169 - val_mae: 33.1723\n",
      "Epoch 358/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 14103.4014 - mae: 97.9402 - val_loss: 1431.8494 - val_mae: 33.0254\n",
      "Epoch 359/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 11880.0576 - mae: 72.2628 - val_loss: 1424.7201 - val_mae: 32.9832\n",
      "Epoch 360/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 4478.9565 - mae: 57.0773 - val_loss: 1419.2323 - val_mae: 32.9656\n",
      "Epoch 361/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 11525.6299 - mae: 93.4824 - val_loss: 1414.8717 - val_mae: 32.9743\n",
      "Epoch 362/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9540.8789 - mae: 72.2804 - val_loss: 1412.0841 - val_mae: 33.0018\n",
      "Epoch 363/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 11010.2842 - mae: 74.0533 - val_loss: 1410.6378 - val_mae: 33.0314\n",
      "Epoch 364/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6541.1333 - mae: 62.9513 - val_loss: 1411.9764 - val_mae: 33.1000\n",
      "Epoch 365/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 14381.6953 - mae: 73.0735 - val_loss: 1410.6328 - val_mae: 33.1045\n",
      "Epoch 366/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 17026.3770 - mae: 98.9930 - val_loss: 1410.7928 - val_mae: 33.1311\n",
      "Epoch 367/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 16846.3535 - mae: 109.0425 - val_loss: 1419.0085 - val_mae: 33.2610\n",
      "Epoch 368/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13173.1045 - mae: 96.4027 - val_loss: 1426.5247 - val_mae: 33.3491\n",
      "Epoch 369/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 14051.3652 - mae: 89.7283 - val_loss: 1431.0984 - val_mae: 33.3813\n",
      "Epoch 370/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9565.5332 - mae: 85.6178 - val_loss: 1444.0371 - val_mae: 33.4952\n",
      "Epoch 371/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 20970.5684 - mae: 117.2776 - val_loss: 1451.0802 - val_mae: 33.5214\n",
      "Epoch 372/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 16027.3076 - mae: 92.3886 - val_loss: 1446.5554 - val_mae: 33.4192\n",
      "Epoch 373/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 12234.7373 - mae: 94.6819 - val_loss: 1447.7772 - val_mae: 33.3660\n",
      "Epoch 374/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13778.2354 - mae: 101.0943 - val_loss: 1459.7582 - val_mae: 33.4157\n",
      "Epoch 375/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6389.2251 - mae: 65.8569 - val_loss: 1472.8750 - val_mae: 33.4668\n",
      "Epoch 376/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 17090.7461 - mae: 104.7391 - val_loss: 1471.4751 - val_mae: 33.3892\n",
      "Epoch 377/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7136.2861 - mae: 68.6691 - val_loss: 1473.4279 - val_mae: 33.3457\n",
      "Epoch 378/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 14466.5547 - mae: 95.7370 - val_loss: 1469.8944 - val_mae: 33.2486\n",
      "Epoch 379/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 13851.4639 - mae: 96.2732 - val_loss: 1475.6405 - val_mae: 33.2825\n",
      "Epoch 380/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 11678.5742 - mae: 86.5095 - val_loss: 1491.5059 - val_mae: 33.6879\n",
      "Epoch 381/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 13756.1123 - mae: 93.7727 - val_loss: 1502.0853 - val_mae: 33.9811\n",
      "Epoch 382/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 13424.0332 - mae: 99.6258 - val_loss: 1532.9723 - val_mae: 34.6171\n",
      "Epoch 383/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 16220.5283 - mae: 101.7688 - val_loss: 1539.1765 - val_mae: 34.8191\n",
      "Epoch 384/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 12282.1396 - mae: 77.5921 - val_loss: 1536.4417 - val_mae: 34.8704\n",
      "Epoch 385/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 13986.1016 - mae: 93.6981 - val_loss: 1547.2449 - val_mae: 35.1286\n",
      "Epoch 386/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 5681.3423 - mae: 62.7025 - val_loss: 1550.4912 - val_mae: 35.2609\n",
      "Epoch 387/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 22560.8066 - mae: 123.5834 - val_loss: 1565.2581 - val_mae: 35.5625\n",
      "Epoch 388/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 6463.5796 - mae: 58.1758 - val_loss: 1564.6516 - val_mae: 35.6260\n",
      "Epoch 389/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 17337.8184 - mae: 94.7928 - val_loss: 1563.8756 - val_mae: 35.6890\n",
      "Epoch 390/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10139.4297 - mae: 73.8222 - val_loss: 1565.4099 - val_mae: 35.7829\n",
      "Epoch 391/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 11163.3516 - mae: 82.3214 - val_loss: 1549.3481 - val_mae: 35.6176\n",
      "Epoch 392/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 15090.5820 - mae: 110.1395 - val_loss: 1540.3159 - val_mae: 35.5588\n",
      "Epoch 393/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 12075.5010 - mae: 93.3483 - val_loss: 1539.9832 - val_mae: 35.6209\n",
      "Epoch 394/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10531.6543 - mae: 83.6539 - val_loss: 1530.9170 - val_mae: 35.5521\n",
      "Epoch 395/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 14291.4658 - mae: 89.7246 - val_loss: 1523.9963 - val_mae: 35.5156\n",
      "Epoch 396/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7100.6841 - mae: 73.3439 - val_loss: 1520.4686 - val_mae: 35.5233\n",
      "Epoch 397/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 12059.6221 - mae: 81.1963 - val_loss: 1497.0573 - val_mae: 35.2399\n",
      "Epoch 398/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9351.8809 - mae: 77.5256 - val_loss: 1483.2812 - val_mae: 35.0988\n",
      "Epoch 399/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7987.4448 - mae: 72.1044 - val_loss: 1456.8698 - val_mae: 34.7637\n",
      "Epoch 400/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - loss: 8213.1221 - mae: 66.6134 - val_loss: 1420.6913 - val_mae: 34.2710\n",
      "Epoch 401/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 11009.2520 - mae: 92.6150 - val_loss: 1386.4404 - val_mae: 33.7954\n",
      "Epoch 402/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7949.3438 - mae: 70.0947 - val_loss: 1365.9158 - val_mae: 33.5225\n",
      "Epoch 403/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 12440.2998 - mae: 87.4425 - val_loss: 1343.1954 - val_mae: 33.2059\n",
      "Epoch 404/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9199.3848 - mae: 78.4418 - val_loss: 1327.5933 - val_mae: 32.9999\n",
      "Epoch 405/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9548.5713 - mae: 77.9798 - val_loss: 1320.6458 - val_mae: 32.9326\n",
      "Epoch 406/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7709.9546 - mae: 71.1076 - val_loss: 1318.3906 - val_mae: 32.9406\n",
      "Epoch 407/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 15849.3408 - mae: 92.8602 - val_loss: 1309.8136 - val_mae: 32.8535\n",
      "Epoch 408/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 13322.4785 - mae: 95.6365 - val_loss: 1292.6576 - val_mae: 32.6200\n",
      "Epoch 409/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6023.2148 - mae: 61.2368 - val_loss: 1269.7708 - val_mae: 32.2821\n",
      "Epoch 410/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9915.2842 - mae: 80.9307 - val_loss: 1255.6853 - val_mae: 32.0926\n",
      "Epoch 411/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 6773.1323 - mae: 65.7901 - val_loss: 1232.9436 - val_mae: 31.7536\n",
      "Epoch 412/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7686.2720 - mae: 66.9293 - val_loss: 1212.7344 - val_mae: 31.4367\n",
      "Epoch 413/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - loss: 9046.1689 - mae: 79.9841 - val_loss: 1189.1310 - val_mae: 31.0524\n",
      "Epoch 414/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 13536.4160 - mae: 92.9035 - val_loss: 1163.7678 - val_mae: 30.6248\n",
      "Epoch 415/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4117.5952 - mae: 49.0580 - val_loss: 1141.9366 - val_mae: 30.2415\n",
      "Epoch 416/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7204.7202 - mae: 70.2752 - val_loss: 1115.3275 - val_mae: 29.7280\n",
      "Epoch 417/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9980.4844 - mae: 72.3925 - val_loss: 1086.5730 - val_mae: 29.1416\n",
      "Epoch 418/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10765.9922 - mae: 88.4903 - val_loss: 1057.7963 - val_mae: 28.5214\n",
      "Epoch 419/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8970.2783 - mae: 62.9397 - val_loss: 1038.8623 - val_mae: 28.1220\n",
      "Epoch 420/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 15236.0068 - mae: 92.6206 - val_loss: 1021.5154 - val_mae: 27.7636\n",
      "Epoch 421/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6960.6685 - mae: 67.2250 - val_loss: 1007.2686 - val_mae: 27.4744\n",
      "Epoch 422/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 7407.9902 - mae: 69.3880 - val_loss: 996.4777 - val_mae: 27.2874\n",
      "Epoch 423/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6844.2700 - mae: 59.3475 - val_loss: 985.4056 - val_mae: 27.0839\n",
      "Epoch 424/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6055.8052 - mae: 58.3815 - val_loss: 978.4916 - val_mae: 27.0080\n",
      "Epoch 425/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 5392.4780 - mae: 47.9027 - val_loss: 970.5026 - val_mae: 26.8900\n",
      "Epoch 426/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 10522.2520 - mae: 81.6907 - val_loss: 966.7728 - val_mae: 26.9106\n",
      "Epoch 427/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - loss: 9048.4971 - mae: 68.7118 - val_loss: 963.7845 - val_mae: 26.9409\n",
      "Epoch 428/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 17891.1484 - mae: 101.6515 - val_loss: 963.1650 - val_mae: 27.0566\n",
      "Epoch 429/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7304.5410 - mae: 70.5641 - val_loss: 969.3301 - val_mae: 27.3788\n",
      "Epoch 430/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4602.6646 - mae: 61.9608 - val_loss: 970.9508 - val_mae: 27.5452\n",
      "Epoch 431/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 7507.2822 - mae: 64.6543 - val_loss: 965.7079 - val_mae: 27.5254\n",
      "Epoch 432/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8588.3916 - mae: 77.6373 - val_loss: 960.5112 - val_mae: 27.5207\n",
      "Epoch 433/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 4715.7593 - mae: 53.6347 - val_loss: 953.5076 - val_mae: 27.4636\n",
      "Epoch 434/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6383.3062 - mae: 64.7981 - val_loss: 949.6100 - val_mae: 27.4856\n",
      "Epoch 435/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 11046.5000 - mae: 74.6928 - val_loss: 933.4276 - val_mae: 27.1749\n",
      "Epoch 436/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6331.1045 - mae: 65.8096 - val_loss: 923.7555 - val_mae: 27.0309\n",
      "Epoch 437/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 9986.6846 - mae: 80.5687 - val_loss: 922.2726 - val_mae: 27.1161\n",
      "Epoch 438/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9541.1641 - mae: 77.1430 - val_loss: 920.2094 - val_mae: 27.1666\n",
      "Epoch 439/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 9521.4980 - mae: 77.1905 - val_loss: 922.7216 - val_mae: 27.3229\n",
      "Epoch 440/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - loss: 9418.0430 - mae: 87.1353 - val_loss: 921.5833 - val_mae: 27.3879\n",
      "Epoch 441/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 5640.1646 - mae: 56.0830 - val_loss: 922.4230 - val_mae: 27.5103\n",
      "Epoch 442/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 10577.0498 - mae: 79.5862 - val_loss: 922.3516 - val_mae: 27.6164\n",
      "Epoch 443/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 4279.4336 - mae: 54.4626 - val_loss: 914.4166 - val_mae: 27.5183\n",
      "Epoch 444/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 5699.8247 - mae: 61.1861 - val_loss: 902.9881 - val_mae: 27.3284\n",
      "Epoch 445/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 8866.4795 - mae: 79.7218 - val_loss: 893.5883 - val_mae: 27.1932\n",
      "Epoch 446/10000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5953.0410 - mae: 65.8401"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "\n",
    "random_seed = 60\n",
    "tf.random.set_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "import random\n",
    "random.seed(random_seed)\n",
    "\n",
    "# Load data from CSV file\n",
    "df = pd.read_csv(r\"/Users/avniguota/Desktop/nir sensor/ORANGE_DATA_FINAL.csv\")\n",
    "\n",
    "# Extract features and target variable\n",
    "x = df.iloc[:, :18].to_numpy()  # Features\n",
    "y = df.iloc[:, 18].to_numpy()    # Target variable\n",
    "\n",
    "# Split data into training and testing sets\n",
    "seed = 21\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Define the neural network model\n",
    "model_bpnn = Sequential([\n",
    "    Dense(24, input_dim=18, activation='relu'),  # Hidden layer with ReLU activation\n",
    "    Dropout(0.2),  # Dropout layer with 20% dropout rate\n",
    "    Dense(1, activation='linear')  # Output layer with linear activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_bpnn.compile(\n",
    "    loss='mean_squared_error',  # Loss function\n",
    "    optimizer=Adam(learning_rate=0.001),  # Optimizer with a learning rate of 0.001\n",
    "    metrics=['mae']  # Metric to evaluate\n",
    ")\n",
    "\n",
    "# Print model summary\n",
    "model_bpnn.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model_bpnn.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=10000,          # Number of epochs\n",
    "    batch_size=32,     # Batch size\n",
    "    verbose=1,         # Verbosity mode\n",
    "    validation_split=0.2  # Fraction of training data to be used as validation data\n",
    ")\n",
    "\n",
    "# Evaluate the model on training and testing data\n",
    "train_loss, train_mae = model_bpnn.evaluate(x_train, y_train, verbose=0)\n",
    "test_loss, test_mae = model_bpnn.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Training MAE: {train_mae:.2f}')\n",
    "print(f'Testing MAE: {test_mae:.2f}')\n",
    "\n",
    "# Plot training and validation loss\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = model_bpnn.predict(x_test).flatten()\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE)\n",
    "mape_bpnn = mean_absolute_percentage_error(y_test, predictions) * 100\n",
    "print(f'MAPE for BPNN: {mape_bpnn:.2f}%')\n",
    "\n",
    "# Print actual vs. predicted values\n",
    "print(\"{:<15s}{:<15s}\".format(\"Actual BRIX\", \"Predicted BRIX\"))\n",
    "for actual, predicted in zip(y_test, predictions):\n",
    "    print(\"{:<15.2f}{:<15.2f}\".format(float(actual), float(predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a265c2e-626f-4f0f-ae03-46463e05f45c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
